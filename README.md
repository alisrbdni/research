# Federated Learning Research Repository for Natural Language Processing

Welcome to our dedicated repository for cutting-edge research in federated learning applied to natural language processing. This collection of notebooks is designed to help researchers and practitioners explore various techniques in language model training in a decentralized and privacy-preserving manner.

# Federated Learning Research Repository for Natural Language Processing

Welcome to our dedicated repository for cutting-edge research in federated learning applied to natural language processing. This collection of notebooks is designed to help researchers and practitioners explore various techniques in language model training in a decentralized and privacy-preserving manner.

## Repository Structure

Below is a quick overview of the repository's content:

- **papers/**: Contains research papers and related documents.
-  **LLM_fine_tuning_with_Flower.ipynb**: Notebook for fine-tuning large language models using the Flower framework.
- **Federated_learning_with_flower_nlp_MLM_albert_base_v2.ipynb**: Notebook for federated learning with masked language modeling using ALBERT.
- **MNIST_Flower_Simulation.ipynb**: Explore federated learning simulations with the classic MNIST dataset.
- **README.md**: This file, which provides an overview and guide for the repository.

## Interactive Notebooks

All notebooks are fully interactive and can be run directly in Google Colab to ensure easy access and a practical, hands-on experience. Simply click on the "Open in Colab" badge to start experimenting with the models.

### Notebooks List

1. **LLM Fine-Tuning with Flower**: Dive into federated learning by fine-tuning large language models using the Flower framework. This notebook provides a comprehensive guide to setting up and running federated learning experiments with state-of-the-art language models.
   
   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/alisrbdni/research/blob/main/LLM_fine_tuning_with_Flower.ipynb)

2. **Federated Learning With Flower for NLP albert_base_v2**: This notebook explores techniques federated learning setting, ensuring data privacy while extracting meaningful insights from distributed text data.

   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/alisrbdni/research/blob/main/Federated_learning_with_flower_nlp_MLM_albert_base_v2.ipynb)

3. **MNIST Flower Simulation**: Get hands-on experience with federated learning using the MNIST dataset, simulating the collaborative training of a neural network model across multiple decentralized nodes.
   
   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/alisrbdni/research/blob/main/MNIST_Flower_Simulation.ipynb)


## Getting Started

To run the notebooks:
- Click on the "Open in Colab" badge next to the notebook title.
- Colab will open with the notebook loaded. Follow the instructions within the notebook to install any required dependencies and run the cells.

## Contribute

We welcome contributions from the community. If you have an idea for a new federated learning experiment or improvements to existing ones, please feel free to fork this repository, make your changes, and submit a pull request.

## Support

For support, please open an issue in the repository with a detailed description of your problem or suggestion. We strive to respond promptly and help resolve any issues you encounter.
